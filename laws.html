<!DOCTYPE html>
<html lang="en">
<header>
    <link rel="stylesheet" href="style.css" />
    <link rel="scsssheet" href="style.scss"/>
    <title>AI Laws</title>
</header>
    
    
    
    
    
    <header>

    <br>

           <ul style="margin-left:95px;">

         <h1 class="highlighter"> Artificial Intelligence</h1>
         <li id="extra"> <a href="Extra.html"> AI Info</a></li>
         <li id="laws"> <a href="laws.html" class="active"> Laws</a></li>
         <li id="home" style="font-size:28px;"> <a href="index.html"> Home</a></li>
         <li id="types"> <a href="types.html">AI Types</a></li>
         <li id="credits"> <a href="credits.html"> About</a></li>
         <li id="contact"> <a href="https://www.youtube.com/watch?v=l-7fTrL4jv4"> WEEZER</a></li>
    
        </ul>
    
        <br>
    
    </header>

    <body>

        <div class="background5" />


        <!-- header -->
        <h1 class="highlighter"> Current Canadian AI Regulation</h1>

        <br>
        <hr>
        <br>

        <!-- body with underline -->
        <h2 style="text-decoration:underline;" class="highlighter">Canadian AI Regulation: BILL C-27 and AIDA</h2>

        <br>
        <hr>
        <br>
        
        <!-- body with underline -->
        <h2 class="highlighter"> Three Parts of Bill C-2 </h2>

        <br>

        <!-- body -->

        <ol>
            <h3 style="margin:auto;" class="highlighter"> Part 1</h3>

         <li> <p class="textbox box" style="margin: auto;"> enacts the Consumer Privacy Protection act. This act ensures the protection of personal information while balancing what data organizations need to collect for use, disclose, or for commercial use. And as a note it takes back some statements of Part 1 of the Personal Information Protection and Electronic Documents Act. </p>

        <br>

            <h3 style="margin:auto;" class="highlighter">Part 2</h3>

        <li><p  style="margin: auto;" class="textbox box">Performs the Personal Information and Data Protection Tribunal Act. What this act means is that one that administrates tribunal (a type of court that is set up to deal with a specific kind of legal dispute/matter. Usually less formal than a traditional court and is used to resolve conflicts between individuals or organizations.) to concede appeals. </p> </li>
        <br>

            <h3 style="margin:auto;" class="highlighter"> Part 3</h3>

        <li><p  style="margin:auto;" class="textbox box">Part three enacts the Artificial Intelligence and Data Act (AIDA), Which will be the majority of the information below.</p></li>

    </ol>

    <h2 style="color:white;" class="highlighter">A</h2>

    <br>
    <hr>
    <br>

        <!-- body with underline -->
        <h2 class="highlighter">Part 3: AIDA</h2>

        <br>
        <hr>
        <br>

        <!-- body -->

    

        <p style="margin:auto;" class="textbox box">AIDA is a data act enforced upon Artificial Intelligence. Knowing that AI will have an impact on the operations on Canadian businesses, and the lives of Canadians as a whole. This documentation aims to reassure Canadians in the AI system in Canada that the aim of these laws is not to entrap AI or to limit AI, but to regulate the most powerful uses of AI that it possesses to cause harm. Specifically, the act intended to address the concerns of AI and provide assurance to Canadians that the risks owned by AI will not slip through the cracks of human rights and the protection of Canada, within the laws of the Privacy Act, Financial Administration Act, Canada Consumer Product Safety Act and the Criminal Act Of Canada. AIDA ensures that Canadians are able to trust the new technologies of the design, development, and the use of AI. Practically the framework in AIDA is to guide AI navigation to a positive direction. "The Government intends to build on this framework through an open and transparent regulatory development process." This encourages Canadians and Canadian businesses to adopt AI technologies.</p>



        <!-- body with underline -->

        <br>
        <hr>
        <br>


        <h2 style="margin: auto;" class="highlighter">AIDA Proposes Required Basic Steps for AI</h2>

        <br>
        <hr>
        <br>

        <!-- list with description -->

        

            <br>

            <ol>
        
        <li class="highlighter">1&#41; Human Oversight & Monitoring</li>

        <br>

            <p style="margin:auto;" class="textbox box">Human Oversight means that high-impact AI systems must be designed and developed in such a way as to enable people managing the operations of the system to exercise meaningful oversight. This includes a level of interpretability appropriate to the context."</p>

            <br>

            <p style="margin:auto;" class="textbox box">"Monitoring, through measurement and assessment of high-impact AI systems and their output, is critical in supporting effective human oversight."</p>

            <br>

            <li class="highlighter">2&#41; Transparency</li>

            <br>

            <p style="margin:auto;" class="textbox box">"Transparency means providing the public with appropriate information about how high-impact AI systems are being used</p>
            
            <br> 

            <p style="margin:auto;" class="textbox box">The information provided should be sufficient to allow the public to understand the capabilities, limitations, and potential impacts of the systems."</p>

            <li class="highlighter">3&#41; Fairness and Equity</li>

            <br>

            
            <p style="margin:auto;" class="textbox box">Fairness and Equity means building high-impact AI systems with an awareness of the potential for discriminatory outcomes."</p>

            <br> 

            <p style="margin:auto;" class="textbox box">appropriate actions must be taken to mitigate discriminatory outcomes for individuals and groups."</p>

            <li class="highlighter">4&#41; Safety</li>

            <br>

            <p style="margin:auto;" class="textbox box">"systems must be proactively assessed to identify harms that could result from use of the system, including through reasonably foreseeable misuse."  "Measures must be taken to mitigate the risk of harm."</p>
            <br>
           


            <li class="highlighter"> 5&#41; Accountability</li>

            <br>

            <p style="margin:auto;" class="textbox box">Accountability means that organizations must put in place governance mechanisms needed to ensure compliance with all legal obligations of high-impact AI systems in the context in which they will be used."</p>
            <br> 
            <p style="margin:auto;" class="textbox box">"This includes the proactive documentation of policies, processes, and measures implemented."</p>

        <li class="highlighter">6&#41; Validity & Robustness</li>

        <p style="margin:auto;" class="textbox box">Validity means a high-impact AI system performs consistently with intended objectives."</p>

        <br>

        <p style="margin:auto;" class="textbox box">Robustness means a high-impact AI system is stable and resilient in a variety of circumstances."</p>

    </ol>

        <!-- body with underline -->

        <br>
        <hr>
        <br>
        
        <h2 class="highlighter">Enforced Offenses to the Public</h2>


        <!-- list -->
        <ol>

            <br>
            <hr>
            <br>

        <h3 class="highlighter"> Conditions of Crimes</h3>
            
            <p style="margin:auto;" class="textbox box"> 1&#41; Knowing and/or believing that the use of an artificial intelligence system is to cause psychological, or physical harm to individuals or an individuals' property, </p>
        
            <p style="margin:auto;" class="textbox box"> 2&#41; Mr with intent to use provided prompts, or the system itself to defraud any public identity, and/or to cause any sort of economic loss to individuals.</p>
        
            <p style="margin:auto;" class="textbox box"> 3&#41; Makes an/the artificial intelligence system available for use with its purpose/intent being to cause harm or damage within these reasons.</p>

        </ol>

        <!-- body -->

        <p style="margin:auto;" class="textbox box">The punishments that are enforced to the public are fined to a number less than 25,000,000 and 5% of the offender's gross global revenues within the financial year before the offender was sentenced.</p>

        <br> 
        <hr>
        <br>

        <p style="margin-right:auto;" class="highlighter">Unmentioned</p>


        <br>
        <hr>
        <br>

        <p style="margin:auto;" class="textbox box"> 1&#41; there are some points worth mentioning that this document does not mention regarding AI, likewise in how they say themselves what actions a company should take to ensure accountability for faulty use. With that addressed, They state that: </p>
        <br>
        <!-- list -->
        <p style="margin:auto;" class="textbox box"> 2&#41; Businesses who design or develop a high-impact AI system should be expected to take measures to identify and address risks in regard to harm and bias, document appropriate use and limitations, and adjust the measures as needed. </p>

        <br>
        
        <p style="margin:auto;" class="textbox box"> 3&#41; Businesses who make a high-impact AI system available for use should be expected to consider potential uses when deployed and take measures to ensure users are aware of any restrictions on how the system is meant to be used and understand its limitations.</p>

        <br>

        <p style="margin:auto;" class="textbox box"> 4&#41; Businesses who manage the operations of an AI system should be expected to use AI systems as indicated, assess and mitigate risk, and ensure ongoing monitoring of the system.</p>

        <br>
        <h2 style="color:white;" class="highlighter">A</h2>
        <br>

        <!-- body -->


        <p style="margin:auto;" class="textbox box">The following section explains and provides an example that if a company's AI is able to perform applicable functions such as text, audio, and/or video generation used in a variety of different contexts. Developers of these systems would need to eliminate the risks related to bias and harmful content in documentation and reference used to train the AI.</p>

        <br>

        <p style="margin:auto;" class="textbox box">To a more serious matter, how AI usage comes into true criminal offenses is the intentional behavior where a person causes serious harm. The example stated is that a person could be prosecuted if an AI system made by them or available online was used to cause serious harm and were aware of such to not take appropriate action to prevent it.</p>

        <br>

        <p style="margin:auto;" class="textbox box">This was just a taste of what Canada has put forward, most likely as a reaction of how AI is rapidly changing the economic terrain. We expect further implementation of the further types of AI impacting more communities and law regarding more situations.</p>

        <!-- transition -->
        <!-- transition -->
        <!-- transition -->



 
        <br>
        <li class="highlighter"> America's Perspective </li>
        <br>

        <p style="margin:auto;" class="textbox box">Currently, the main proposal of regulation within AI is a blueprint. The Blueprint for an AI Bill of Rights. Blueprint meaning that "this is what an ideal documentation of what"</p>

        <br>

        <p style="margin:auto;" class="textbox box"> The Bill identifies 5 main principles that focuses on the design, use and deployment of Artificial Intelligence. Again, to protect the peoples of the country. As to the same reasons that canada protects its people, this Bill focuses on protection</p>

        <!-- body with underline -->

        <br>
        <hr>
        <br>


        <h2 class="highlighter">5 Main Sections of America's Blueprint</h2>

        <br>
        <hr>
        <br>

        <!-- list -->
        <li class="highlighter">Safe and Effective Systems:</li>

        <br>

        <p style="margin:auto;" class="textbox box">To be protected from unsafe or ineffective systems, stating that automated systems should be developed with input and discussion from diverse communities and experts to undergo and identify the risks and impacts on America as a whole. Protected from the irrelevant or inappropriate data use in the design and development, Reducing risks with misuse to these systems. To ensure the safety of American citizens. </p>

        <br>

        <li class="highlighter">Algorithmic Discrimination Protections:</li>

        <br>

        <p style="margin:auto;" class="textbox box"> Systems should not be able to produce any discrimination even when elaborately fed with data. Systems should be used and designed appropriately. Automated systems should not have the ability to contribute to unjustified different treatment disfavoring people of the diverse population protected by law. With such generated discrimination violates legal protection, as to the developers of the system. Implementation of if such situation is to occur should be held in place within the machine.</p>

        <br>

        <li class="highlighter">Data Privacy:</li>

        <br>

        <p style="margin:auto;" class="textbox box">Protection from abusive data practices should be implemented by built-in protective mechanisms and strong data privacy regulations. To encourage the use of a reason of why and how organizations are using your data and their repercussions if the situation of misuse is to occur. Consent plays a huge part in this system, and it's important that People are able to use these tools without the fear of coercion or manipulation by the system itself, or violators. Taking into account that AI will be able to be implemented into systems like Schools, Law, Work, Housing, finance or other contexts provided that AI potentially manifests on impacting.</p>

        <br>

        <br>
        <hr>
        <br>

        <li class="highlighter">Notice and Explanation</li> 

        <br>
        <hr>
        <br>

        <p style="margin:auto;" class="textbox box">Americans should have the education of how an automated system contributes to try to understand the impacts and the outcomes of its content. Those who partake in the process of developing AI should provide accessible language that is interpretable of those that don't have the advantage of complicated interpretability. Knowing those associated to the development of the AI is also responsible for the system, and those who use it. Accessability is the main goal of this section. People should know based on the outcome of the system the impact and the outcome determined by the automated system. This is to respect the idea of the response of the machine, as well as the people whenever possible.</p> 

        <br>

        <li class="highlighter">Human Alternatives Consideration, and Fallback:</li>

        <br>

        <p style="margin:auto;" class="textbox box">Americans should have the ability, where liable, to have the secure choice to consider furthering not to interact with automated systems in favour to a human alternative. To a situation where a machine error is to impact you, you should have the option to appeal or contest to the product made by AI. It should also not impose and unreasonable burden on the public. Systems with intended use within sensitive domains as to employment, health, education, therapy, criminal justice, help, etc... should be tailored to its sole purpose. And as to its purpose, should incorporate human consideration for adverse situations and decisions.</p>

        <br>

        <br>
        <hr>
        <br>

        <li class="highlighter">Summary</li>

        <br>
        <hr>
        <br>


        <p style="margin:auto;" class="textbox box"> The Canadian government has put up a regulation on AI, which is called BILL C-27. Within the bill is The Artificial Intelligence and Data Act (AIDA). AIDA is a data act enforced upon Artificial Intelligence, which aims to regulate the most powerful uses of AI that could cause harm. The framework in AIDA guides AI navigation to a positive direction through ensuring that these basic steps are required: human Oversight & Monitoring, Transparency, Fairness and Equity, Safety, Accountability, Validity & Robustness. The offenses that are enforced to the public are also mentioned, which include committing crimes under certain conditions such as knowingly causing psychological or physical harm to individuals or property, using AI to defraud public identity, or causing economic loss to individuals. The punishments that are enforced to the public are fines to a number less than 25,000,000 and 5% of the offender's gross global revenues within the financial year before the offender was sentenced. The document also mentions that there are some points worth mentioning regarding AI that the document does not mention, such as what actions a company should take to ensure accountability for faulty use.
        

    </body>
    
    </html>